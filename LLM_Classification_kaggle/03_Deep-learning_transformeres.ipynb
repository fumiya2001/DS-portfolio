{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e991ef9c",
   "metadata": {},
   "source": [
    "## Fine-tuning DeBERTa-v3\n",
    "\n",
    "In this notebook, I will fine-tune the entire DeBERTa-v3 model specifically for the disaster tweet classification task.\n",
    "\n",
    "Fine-tuning allows the model's internal weights to adapt to the specific vocabulary and nuances of the disaster dataset, potentially capturing complex linguistic patterns that static embeddings might miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7af23f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_path = \"data/nlp-getting-started.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa55a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd9edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe0bef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b390d0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12d968bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(id             0\n",
       " keyword       61\n",
       " location    2533\n",
       " text           0\n",
       " target         0\n",
       " dtype: int64,\n",
       " (7613, 5))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum(), df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76c534b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       26\n",
       "location    1105\n",
       "text           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61a7a313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='target'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['target'].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0251b2",
   "metadata": {},
   "source": [
    "Dataset Preparation\n",
    "\n",
    "- The pandas DataFrames are converted into Hugging Face `Dataset` objects.\n",
    "\n",
    "- The training dataset is split into training and validation subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d6f3600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "raw_datasets = Dataset.from_pandas(df)\n",
    "raw_test_datasets = Dataset.from_pandas(df_test)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": raw_datasets,\n",
    "    \"test\": raw_test_datasets\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6135578c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'keyword', 'location', 'text', 'target'],\n",
       "        num_rows: 6090\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'keyword', 'location', 'text', 'target'],\n",
       "        num_rows: 1523\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'keyword', 'location', 'text'],\n",
       "        num_rows: 3263\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": split[\"train\"],\n",
    "    \"validation\": split[\"test\"],\n",
    "    \"test\": dataset[\"test\"]\n",
    "})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f67b2",
   "metadata": {},
   "source": [
    "### Tokenizer and Model\n",
    "\n",
    "I used DeBERTa-v3-base as the backbone model.\n",
    "\n",
    "Reasons for this choice:\n",
    "- strong performance on NLP classification tasks\n",
    "- efficient attention mechanism\n",
    "- availability of high-quality pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c1c1126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"microsoft/deberta-v3-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_fast=False)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36d4d64",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Text data must be converted into numerical representations.\n",
    "\n",
    "The tokenization function:\n",
    "- truncates long sequences\n",
    "- prepares inputs compatible with the Transformer model\n",
    "\n",
    "This function will be applied to the entire dataset in a batched manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16f58f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13baa947602e488798cfd7b4c8f440b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6090 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ede4764f8b4d9baaff7728fa5efb8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1523 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1102dea8324f95b3ce37fc9b4e76d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3263 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'keyword', 'location', 'text', 'target', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 6090\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'keyword', 'location', 'text', 'target', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1523\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'keyword', 'location', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3263\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39a731d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset[\"train\"] = tokenized_dataset[\"train\"].rename_column(\"target\", \"labels\")\n",
    "tokenized_dataset[\"validation\"] = tokenized_dataset[\"validation\"].rename_column(\"target\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df38081a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'keyword', 'location', 'text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 6090\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'keyword', 'location', 'text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1523\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'keyword', 'location', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3263\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee547a7",
   "metadata": {},
   "source": [
    "### Dynamic Padding with DataCollator\n",
    "Instead of padding all sequences to a fixed maximum length,\n",
    "we use a `DataCollatorWithPadding`.\n",
    "\n",
    "This approach:\n",
    "- pads sequences dynamically per batch\n",
    "- reduces unnecessary computation\n",
    "- improves training efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6f29b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "389984b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23, 37, 36, 28, 50, 31, 33, 57, 44, 11]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check about DataCollatorWithPadding\n",
    "samples = tokenized_dataset[\"train\"][:10]\n",
    "samples = {k:v for k, v in samples.items() if k not in ['id','keyword','location','text']}\n",
    "[len(x) for x in samples['input_ids']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "228990ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': torch.Size([10]),\n",
       " 'input_ids': torch.Size([10, 57]),\n",
       " 'token_type_ids': torch.Size([10, 57]),\n",
       " 'attention_mask': torch.Size([10, 57])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator(samples)\n",
    "{k:v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2947be",
   "metadata": {},
   "source": [
    "### Training Configuration\n",
    "Training behavior is controlled using `TrainingArguments`, including:\n",
    "- batch size\n",
    "- learning rate\n",
    "- number of epochs\n",
    "- evaluation strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcddc9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test-trainer\",\n",
    "                                  eval_strategy=\"epoch\",\n",
    "                                  save_strategy=\"no\",\n",
    "                                  per_device_train_batch_size=4,\n",
    "                                  per_device_eval_batch_size=4,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  weight_decay=0.01,\n",
    "                                  num_train_epochs=2,\n",
    "                                  report_to=\"none\",\n",
    "                                  seed=42,\n",
    "                                  data_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e4c7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate \n",
    "def compute_metrics(eval_preds):\n",
    "    metrics = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metrics.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40efbacf",
   "metadata": {},
   "source": [
    "### Trainer Setup\n",
    "The Hugging Face `Trainer` class is used to abstract:\n",
    "- training loop\n",
    "- evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9080a72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24418b46",
   "metadata": {},
   "source": [
    "### Fine-tuning the Transformer Model\n",
    "\n",
    "At this stage, I fine-tune a pretrained DeBERTa-v3-base model on the disaster tweet classification task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0faf5c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 1}.\n",
      "/opt/anaconda3/envs/llm/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3046' max='3046' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3046/3046 14:51, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.546000</td>\n",
       "      <td>0.486545</td>\n",
       "      <td>0.824688</td>\n",
       "      <td>0.785886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>0.561648</td>\n",
       "      <td>0.841760</td>\n",
       "      <td>0.807046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3046, training_loss=0.5196290620439395, metrics={'train_runtime': 893.5945, 'train_samples_per_second': 13.63, 'train_steps_per_second': 3.409, 'total_flos': 284467207889808.0, 'train_loss': 0.5196290620439395, 'epoch': 2.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "768e115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llm/lib/python3.11/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b194a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(predictions.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b77d86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv(\"data/sample_submission.csv\")\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9eda7136",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit[\"target\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96718da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(\"submit_folder/fine_tune_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bcce5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
